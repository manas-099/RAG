{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KoFWGXYmjUJx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain_community chromadb langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxCcnNV3kiX6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ypk3U0YcV9ZN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032\",),\n",
        "\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HSuN2ed0j51p"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=hf_embeddings)\n",
        "\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GY_C8CqSWTm0"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
        "Generate multiple search queries related to: {question} \\n\n",
        "Output (5 queries):\"\"\"\n",
        "\n",
        "prompt_q = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNUISYokk4XU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GROQ_API_KEY']=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "USOELrqAlRt7"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hWJkyXoallwi"
      },
      "outputs": [],
      "source": [
        "llm=ChatGroq(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qDoaJ0L5ksXg"
      },
      "outputs": [],
      "source": [
        "generate_queries_chain=(\n",
        "    prompt_q\n",
        "    |llm\n",
        "    |StrOutputParser()\n",
        "    |(lambda x:x.split(\"\\n\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1K4jEmlvfX",
        "outputId": "559fd841-c617-49b7-a71a-ad082aaccdad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1. \"What is the meaning of LLM alignment in machine learning?\"',\n",
              " '2. \"How does LLM alignment work in natural language processing?\"',\n",
              " '3. \"What is the significance of LLM alignment in language models?\"',\n",
              " '4. \"What are the different types of LLM alignment techniques?\"',\n",
              " '5. \"What are the applications of LLM alignment in artificial intelligence?\"']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query=\"what is llm allignment?\"\n",
        "generate_queries_chain.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8INOVbxUmr_w"
      },
      "outputs": [],
      "source": [
        "from langchain.load import loads,dumps\n",
        "def rrf(document:list[list],k=60):\n",
        "  scores={}\n",
        "  for sub_doc in document:\n",
        "    for rank ,doc in enumerate(sub_doc):\n",
        "      doc_str=dumps(doc)\n",
        "      if doc_str not in scores:\n",
        "        scores[doc_str]=0\n",
        "      else:\n",
        "        scores[doc_str]+=1/(k+rank)\n",
        "  sorted_docs=sorted(scores.items(),key=lambda item:item[1],reverse=True)\n",
        "  sorted_docs=[loads(doc) for doc,_ in sorted_docs]\n",
        "  return sorted_docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VzOe2P4doAgp"
      },
      "outputs": [],
      "source": [
        "retrieve_chain=generate_queries_chain|retriever.map()|rrf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "868bVZnml2l_"
      },
      "outputs": [],
      "source": [
        "rag_template=\"\"\"Generate answer to the user input query based on the context.\n",
        "here is the context:{context}\n",
        "here is the query:{query}\n",
        "\n",
        "\"\"\"\n",
        "prompt=ChatPromptTemplate.from_template(rag_template)\n",
        "\n",
        "rag_chain=(\n",
        "    {\"context\":retrieve_chain,\"query\":RunnablePassthrough()}\n",
        "    |prompt\n",
        "    |llm\n",
        "    |StrOutputParser()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "iv0L3awsoWA1",
        "outputId": "b74c68ac-5754-4a5f-8e0d-ebc28b62032d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-3093935de6b0>:12: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
            "  sorted_docs=[loads(doc) for doc,_ in sorted_docs]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"LLM alignment is a process that trains a large language model (LLM) to ensure that the generated outputs align with human values and goals. This is also called preference optimization, which involves adjusting the LLM's behavior to better match human preferences. There are various alignment methods in research literature, but three popular ones include RLHF (Reinforcement Learning with Human Feedback), which involves training an LLM in two steps using human feedback.\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query=\"what is llm allignment?\"\n",
        "rag_chain.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h6XxGIapokt",
        "outputId": "3f858dbd-9146-4ac3-8000-f9fb6ec12bf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x788b8f740ad0>, search_kwargs={})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dense_retriever = retriever\n",
        "dense_retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oX_hqgOkp6LD"
      },
      "outputs": [],
      "source": [
        "!pip -q install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nBcdhnXooadl"
      },
      "outputs": [],
      "source": [
        "##Reranking uing Ensemble retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "bm2retriever=BM25Retriever.from_documents(splits)\n",
        "ensemble_retriever=EnsembleRetriever(\n",
        "    retrievers=[bm2retriever,dense_retriever],\n",
        "    weights=[0.5,0.5]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qxJoxmTpDHJ",
        "outputId": "d2f9b60b-819f-4454-e5ad-7a2b3e3bdc62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='helpful, safe, and reliable as possible. “ In the context of LLMs specifically, alignment is a process that trains an LLM to ensure that the generated outputs align with human values and goals. This is also called as alignment with respect to human preferences, hence “preference optimization”.What'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='such as RLHF became sought after, post the release of GPT-3. Let’s discuss them briefly.First of all, what is AI alignment?Alignment is an emerging field of study where you ensure that an AI system performs exactly what you want it to perform. Think of a framework like Asimov’s Three Laws of'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='and alignment/preference optimization is performed in a single step. This is because the fine-tuning step, while allowing the model to specialize to tasks and domains, it can also increase the probability of undesired responses from the model.ORPO combines the steps using a single objective'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='methodsVijayasri Iyer·Follow3 min read·Apr 29, 2024--ListenShareWith the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as RLHF became sought after, post the'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='in several settings.ORPO (Odds Ratio Preference Optimization):The newest method so far, ORPO combines Step 2, 3 & 4 into a single step — so the dataset required for this method is a combination of a fine-tuning + preference dataset.The supervised fine-tuning and alignment/preference optimization is'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='A Quick Introduction to LLM Alignment | by Vijayasri Iyer | MediumOpen in appSign upSign inWriteSign upSign inPhoto by Edz Norton on UnsplashA Quick Introduction to LLM AlignmentA speed-dating style introduction to some famous LLM alignment methodsVijayasri Iyer·Follow3 min read·Apr 29,'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='preferences, hence “preference optimization”.What are the current methods for LLM alignment?You will find many alignment methods in research literature, we will only stick to 3 alignment methods for the sake of discussion.RLHF (Reinforcement Learning with Human Feedback):Step 1 & 2: Train an LLM')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "query=\"what is llm allignment?\"\n",
        "ensemble_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "a4qTvTU9qGCv"
      },
      "outputs": [],
      "source": [
        "retrieve__rerank_data=generate_queries_chain|ensemble_retriever.map()|rrf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PzdgfDnNwxUD"
      },
      "outputs": [],
      "source": [
        "data=retrieve__rerank_data.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VMGORui0qwFL"
      },
      "outputs": [],
      "source": [
        "rag_chain=(\n",
        "    {\"context\":retrieve__rerank_data,\"query\":RunnablePassthrough()}\n",
        "    |prompt\n",
        "    |llm\n",
        "    |StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "rBbH9zsPq_U-",
        "outputId": "165bd024-33bf-4500-e092-01508e9c7993"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"LLM alignment is the process of training a large language model (LLM) to ensure that the generated outputs align with human values and goals. This is also called preference optimization, which means optimizing the LLM's preferences to match human preferences. There are various methods for LLM alignment, and one of the popular ones is Reinforcement Learning with Human Feedback (RLHF). RLHF involves training an LLM in three steps: pre-training for the base model, supervised/instruction fine-tuning for a chat variant, and using an ancillary language model to learn human preferences through a preference dataset. The ancillary language model can be much smaller than the main LLM. The LLM is then trained to distinguish between good and bad responses based on the human preferences learned.\""
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "query=\"what is llm allignment?\"\n",
        "rag_chain.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2CmFhKmSrF8G"
      },
      "outputs": [],
      "source": [
        "##Long Context Reorder\n",
        "from langchain_community.document_transformers import  LongContextReorder\n",
        "reordering=LongContextReorder()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXz7bqPhwe-c",
        "outputId": "a9236eb5-a34b-459a-d4d2-40945497d411"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='preferences, hence “preference optimization”.What are the current methods for LLM alignment?You will find many alignment methods in research literature, we will only stick to 3 alignment methods for the sake of discussion.RLHF (Reinforcement Learning with Human Feedback):Step 1 & 2: Train an LLM'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='helpful, safe, and reliable as possible. “ In the context of LLMs specifically, alignment is a process that trains an LLM to ensure that the generated outputs align with human values and goals. This is also called as alignment with respect to human preferences, hence “preference optimization”.What'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='methodsVijayasri Iyer·Follow3 min read·Apr 29, 2024--ListenShareWith the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as RLHF became sought after, post the'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='A Quick Introduction to LLM Alignment | by Vijayasri Iyer | MediumOpen in appSign upSign inWriteSign upSign inPhoto by Edz Norton on UnsplashA Quick Introduction to LLM AlignmentA speed-dating style introduction to some famous LLM alignment methodsVijayasri Iyer·Follow3 min read·Apr 29,'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='methodsVijayasri Iyer·Follow3 min read·Apr 29, 2024--ListenShareWith the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as RLHF became sought after, post the'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='conclusion, we have covered some of the most famous alignment methods briefly here. However, there are many more nuances in the theory and implementation of each of these alignment methods, which can only be gleaned by reading their respective papers. There are also some excellent resources on'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='where the LLM is the agent, the reward model provides a positive or negative reward to the LLM based on how well it’s responses align with the “human preferred responses”.In theory, it is as simple as that. However, implementation isn’t that easy — requiring lot of human experts and compute'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='A Quick Introduction to LLM Alignment | by Vijayasri Iyer | MediumOpen in appSign upSign inWriteSign upSign inPhoto by Edz Norton on UnsplashA Quick Introduction to LLM AlignmentA speed-dating style introduction to some famous LLM alignment methodsVijayasri Iyer·Follow3 min read·Apr 29,'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='with Human Feedback):Step 1 & 2: Train an LLM (pre-training for the base model + supervised/instruction fine-tuning for a chat variant)Step 3: RLHF uses an ancillary language model (it could be much smaller than the main LLM) to learn human preferences. This can be done using a preference dataset —'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='Think of a framework like Asimov’s Three Laws of Robotics as a rough example. A first google search might lead you to this definition by IBM, “Alignment is the process of encoding human values and goals into large language models to make them as helpful, safe, and reliable as possible. “ In the'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='(i.e step 3). How? DPO defines an additional preference loss as a function of it’s policy and uses the language model directly as the reward model. The idea is simple, If you are already training such a powerful LLM, why not train itself to distinguish between good and bad responses, instead of'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='such as RLHF became sought after, post the release of GPT-3. Let’s discuss them briefly.First of all, what is AI alignment?Alignment is an emerging field of study where you ensure that an AI system performs exactly what you want it to perform. Think of a framework like Asimov’s Three Laws of')]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=retrieve__rerank_data.invoke(query)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YI11KI90whun"
      },
      "outputs": [],
      "source": [
        "retrieved_docs=reordering.transform_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aEcW6ixLxVU8",
        "outputId": "ff528213-7106-4192-e766-11ff6e0b7eb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='helpful, safe, and reliable as possible. “ In the context of LLMs specifically, alignment is a process that trains an LLM to ensure that the generated outputs align with human values and goals. This is also called as alignment with respect to human preferences, hence “preference optimization”.What'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='A Quick Introduction to LLM Alignment | by Vijayasri Iyer | MediumOpen in appSign upSign inWriteSign upSign inPhoto by Edz Norton on UnsplashA Quick Introduction to LLM AlignmentA speed-dating style introduction to some famous LLM alignment methodsVijayasri Iyer·Follow3 min read·Apr 29,'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='conclusion, we have covered some of the most famous alignment methods briefly here. However, there are many more nuances in the theory and implementation of each of these alignment methods, which can only be gleaned by reading their respective papers. There are also some excellent resources on'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='A Quick Introduction to LLM Alignment | by Vijayasri Iyer | MediumOpen in appSign upSign inWriteSign upSign inPhoto by Edz Norton on UnsplashA Quick Introduction to LLM AlignmentA speed-dating style introduction to some famous LLM alignment methodsVijayasri Iyer·Follow3 min read·Apr 29,'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='Think of a framework like Asimov’s Three Laws of Robotics as a rough example. A first google search might lead you to this definition by IBM, “Alignment is the process of encoding human values and goals into large language models to make them as helpful, safe, and reliable as possible. “ In the'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='such as RLHF became sought after, post the release of GPT-3. Let’s discuss them briefly.First of all, what is AI alignment?Alignment is an emerging field of study where you ensure that an AI system performs exactly what you want it to perform. Think of a framework like Asimov’s Three Laws of'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='(i.e step 3). How? DPO defines an additional preference loss as a function of it’s policy and uses the language model directly as the reward model. The idea is simple, If you are already training such a powerful LLM, why not train itself to distinguish between good and bad responses, instead of'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='with Human Feedback):Step 1 & 2: Train an LLM (pre-training for the base model + supervised/instruction fine-tuning for a chat variant)Step 3: RLHF uses an ancillary language model (it could be much smaller than the main LLM) to learn human preferences. This can be done using a preference dataset —'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='where the LLM is the agent, the reward model provides a positive or negative reward to the LLM based on how well it’s responses align with the “human preferred responses”.In theory, it is as simple as that. However, implementation isn’t that easy — requiring lot of human experts and compute'),\n",
              " Document(metadata={'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en', 'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium'}, page_content='methodsVijayasri Iyer·Follow3 min read·Apr 29, 2024--ListenShareWith the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as RLHF became sought after, post the'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='methodsVijayasri Iyer·Follow3 min read·Apr 29, 2024--ListenShareWith the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as RLHF became sought after, post the'),\n",
              " Document(metadata={'source': 'https://vijayasriiyer.medium.com/a-quick-introduction-to-llm-alignment-cad91d09c032', 'title': 'A Quick Introduction to LLM Alignment | by Vijayasri Iyer | Medium', 'description': 'With the rise of LLMs, we have also seen a term called alignment becoming highly popularized in AI literature. Although the field of study existed before, the rise of alignment techniques such as…', 'language': 'en'}, page_content='preferences, hence “preference optimization”.What are the current methods for LLM alignment?You will find many alignment methods in research literature, we will only stick to 3 alignment methods for the sake of discussion.RLHF (Reinforcement Learning with Human Feedback):Step 1 & 2: Train an LLM')]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "qPuFwLyUy97y",
        "outputId": "db9304a2-42c5-4565-9c00-16f1108de5ab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"LLM alignment is the process of training a large language model (LLM) to ensure that its generated outputs align with human values and goals. This is also referred to as alignment with respect to human preferences, or preference optimization. There are various methods for LLM alignment, with one popular method being Reinforcement Learning with Human Feedback (RLHF). RLHF involves training an LLM in steps 1 and 2, followed by using an ancillary language model to learn human preferences in step 3. This can be done using a preference dataset, where the LLM is the agent and the reward model provides a positive or negative reward based on how well the LLM's responses align with human preferred responses. However, implementation of LLM alignment is not straightforward and requires a lot of human expertise and compute.\""
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You're using the pipe operator (|) to create a chain, and the dictionary you're\n",
        "# passing to it is being interpreted as a RunnableParallel which expects its steps\n",
        "#  to be Runnable, Callable, or dict. Since retrieved_docs is a lis\n",
        "rag_chain=(\n",
        "    {\"context\":RunnablePassthrough(),\"query\":RunnablePassthrough()}\n",
        "    |prompt\n",
        "    |llm\n",
        "    |StrOutputParser()\n",
        ")\n",
        "\n",
        "query=\"what is llm allignment?\"\n",
        "rag_chain.invoke({\"context\":retrieved_docs,\"query\":query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "95sG9Bj4yyrK"
      },
      "outputs": [],
      "source": [
        "##self querying (metadata retriever)\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
        "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
        "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
        "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
        "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Toys come alive and have a blast doing so\",\n",
        "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
        "        metadata={\n",
        "            \"year\": 1979,\n",
        "            \"director\": \"Andrei Tarkovsky\",\n",
        "            \"genre\": \"thriller\",\n",
        "            \"rating\": 9.9,\n",
        "        },\n",
        "    ),\n",
        "]\n",
        "vectorstore = Chroma.from_documents(docs, hf_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9T8VWvuD0sPc"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.query_constructor.base import AttributeInfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "X5r9XJU80WVT"
      },
      "outputs": [],
      "source": [
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"genre\",\n",
        "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"year\",\n",
        "        description=\"The year the movie was released\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"director\",\n",
        "        description=\"The name of the movie director\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Tb3iILi-3Gf3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install lark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JqQufjlT0oqC"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "document_content_description = \"Brief summary of a movie\"\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm,\n",
        "    vectorstore,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hnD2CRvK4ZFA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLqJERxk2_0S",
        "outputId": "fe3974ba-1a1f-4fd6-e42e-6bdd631aa923"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea'),\n",
              " Document(metadata={'director': 'Andrei Tarkovsky', 'genre': 'thriller', 'rating': 9.9, 'year': 1979}, page_content='Three men walk into the Zone, three men walk out of the Zone')]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIjKsIxy5RMy",
        "outputId": "0dd34e59-9bb2-4b48-8b48-ea267fee7173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lark in /usr/local/lib/python3.11/dist-packages (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "# !pip install lark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlEHlDJW3jeo",
        "outputId": "3104694f-903c-4419-bd9b-87c963ee0a9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'director': 'Greta Gerwig', 'rating': 8.3, 'year': 2019}, page_content='A bunch of normal-sized women are supremely wholesome and some men pine after them')]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"Has Greta Gerwig directed any movies about women\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Vb3faSvM6zqq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PeEIRDVt6GnG",
        "outputId": "044cdf9b-d4dd-4b8c-9cac-bfa1805586b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Based on the provided context, I would recommend the movie \"Stalker\" directed by Andrei Tarkovsky. It has a rating of 9.9, which is higher than 8.5.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain=(\n",
        "    {\"context\":retriever,\"query\":RunnablePassthrough()}\n",
        "    |prompt\n",
        "    |llm\n",
        "    |StrOutputParser()\n",
        ")\n",
        "query=\"I want to watch a movie rated higher than 8.5\"\n",
        "\n",
        "\n",
        "rag_chain.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ckNWf7wf7G3O",
        "outputId": "cf89b584-be66-440d-ac54-a39720671d37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Yes, Greta Gerwig has directed a movie about women. The movie is \"Little Women\" which was released in 2019 and has a rating of 8.3. The movie features a group of normal-sized women who are portrayed as supremely wholesome, and some men pine after them.'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query=\"Has Greta Gerwig directed any movies about women\"\n",
        "rag_chain.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdSLqgMX7NqU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
