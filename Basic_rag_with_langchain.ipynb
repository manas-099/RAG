{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basic RAG \n",
        " This implementation of RAG is inspired by the teachings of  Vasanth P sir Yt channel(Neural Hacks with Vasanth).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqCEf4qC49e8"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv ,find_dotenv\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZXBX5pS5gTi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2']='True'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY']=os.getenv('LANGCHAIN_API_KEY')\n",
        "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "mj1eKGyk5o-c",
        "outputId": "bd7bf6d0-05ad-44d3-96ef-b92862cf63a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A transformer model is a type of deep learning model introduced in 2017, which has become fundamental in natural language processing (NLP) and has been applied to various tasks in machine learning and artificial intelligence. It processes input data through a series of layers containing self-attention mechanisms and feedforward neural networks. Unlike recurrent neural networks (RNNs) and convolutional neural networks (CNNs), transformer models process input sequences in parallel, making them highly efficient for training and inference.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "loader=WebBaseLoader(\n",
        "    web_path=(\"https://www.ibm.com/think/topics/transformer-model\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post_content\",\"cmp-container\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "docs=loader.load()\n",
        "\n",
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
        "chunks_data=text_spliter.split_documents(docs)\n",
        "\n",
        "# Define the model parameters\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "\n",
        "hf_em_model = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "vecotorstore=FAISS.from_documents(\n",
        "    documents=chunks_data,\n",
        "    embedding=hf_em_model\n",
        ")\n",
        "\n",
        "retrive_data=vecotorstore.as_retriever()\n",
        "\n",
        "llm=ChatGroq(\n",
        "    model=\"llama3-8b-8192\", temperature=0\n",
        ")\n",
        "\n",
        "prompt=hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain=(\n",
        "    {\"context\":retrive_data|format_docs,\"question\":RunnablePassthrough()}\n",
        "    |prompt\n",
        "    |llm\n",
        "    |StrOutputParser()\n",
        "\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "iumTDdOm_vOM",
        "outputId": "064f0823-d9c4-443e-98f7-158b36287745"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A transformer model is a type of deep learning model introduced in 2017, which has become fundamental in natural language processing (NLP) and has been applied to various tasks in machine learning and artificial intelligence. It processes input data through a series of layers containing self-attention mechanisms and feedforward neural networks. Unlike recurrent neural networks (RNNs) and convolutional neural networks (CNNs), transformer models process input sequences in parallel, making them highly efficient for training and inference.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"what is Transformer model?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4x5Ax1dBTvl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FjZGpKX0sas"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
